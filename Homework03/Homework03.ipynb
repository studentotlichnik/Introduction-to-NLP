{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Homework03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_fNT9vW4gKg"
      },
      "source": [
        "# Домашнее задание 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHbhuMmf4gKh"
      },
      "source": [
        "## Тема “Создание признакового пространства”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eARvD2FI4gKi"
      },
      "source": [
        "**Используем предобработанные в рамках 1-ого домашнего задания датасет combine_df_prepocessed.pkl. Используем столбец 'clean_tweet'.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-jNNRJk4gKj"
      },
      "source": [
        "Установим библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaytwc2r4gKj"
      },
      "source": [
        "# !pip install spacy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x34UU_Ot4gKn"
      },
      "source": [
        "# !python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWVB0-yF4gKq"
      },
      "source": [
        "# !pip install deeppavlov spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPvn3tPW4gKt"
      },
      "source": [
        "# !pip install en_core_web_md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_hIjPzf4gKw"
      },
      "source": [
        "# !python -m spacy download en_core_web_md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyHI5Kk14gK0"
      },
      "source": [
        "Подключим библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqOb7u-i4gK0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "import spacy\n",
        "import nltk\n",
        "import en_core_web_sm\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53qYz2-s4gK4"
      },
      "source": [
        "Загрузим данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QJX_IWu4gK5",
        "outputId": "d45b50df-7545-4c44-a320-0d28ca855224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWqtEfYg4gK8"
      },
      "source": [
        "Загрузим модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejteRg-V4gK9"
      },
      "source": [
        "with open('combine_df.pkl', 'rb') as f:\n",
        "    combine_df  = pickle.load(f)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "391AYK1n4gLB",
        "outputId": "df07a5d3-5d45-41d6-f11a-fb419a4e016a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "combine_df.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "      <th>tweet_stemmed</th>\n",
              "      <th>tweet_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
              "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
              "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
              "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
              "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
              "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
              "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
              "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>[bihday, your, majesty]</td>\n",
              "      <td>[bihday, majesty]</td>\n",
              "      <td>[bihday, majesti]</td>\n",
              "      <td>[bihday, majesty]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                   tweet_lemmatized\n",
              "0   1  ...  [father, dysfunctional, selfish, drag, kid, dy...\n",
              "1   2  ...  [thanks, lyft, credit, use, cause, offer, whee...\n",
              "2   3  ...                                  [bihday, majesty]\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2SdAwEX4gLE"
      },
      "source": [
        "**Задание 1.**\n",
        "\n",
        "Используя библиотеку Spacy, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? (Учтите, что max_word_limit_spacy для Spacy = 1000000)\n",
        "\n",
        "С помощью Spacy выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?\n",
        "\n",
        "Повторим шаги из заданий 1 и 2, используя библиотеку nltk.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neXdgxiF4gLF"
      },
      "source": [
        "TOP_LIMIT = 20"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnt5uTiC4gLH",
        "outputId": "74011a3b-3684-4735-ad15-36e28dbdadd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "nlp = en_core_web_sm.load()\n",
        "combine_df['nlp'] = combine_df.clean_tweet.progress_apply(lambda x:  nlp(x))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 49159/49159 [06:06<00:00, 134.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6min 5s, sys: 2.99 s, total: 6min 8s\n",
            "Wall time: 6min 7s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vurh4Vbe4gLK"
      },
      "source": [
        "nlp.max_length = combine_df['nlp'].shape[0]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TNX41Yp4gLQ"
      },
      "source": [
        "labels = []\n",
        "for doc in combine_df['nlp'].tolist():\n",
        "    for e in doc.ents:\n",
        "        labels.append((e.label_, e.text))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUVnoych4gLT"
      },
      "source": [
        "ner_df = pd.DataFrame(labels, columns=['ner', 'word'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqQdSmCv4gLW",
        "outputId": "d97948ec-123c-4211-ea00-4bf4b9bc74ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "ner_df.ner.value_counts().head(TOP_LIMIT)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DATE           12115\n",
              "PERSON          9040\n",
              "ORG             5129\n",
              "GPE             4572\n",
              "TIME            2225\n",
              "NORP            1483\n",
              "CARDINAL        1093\n",
              "ORDINAL          598\n",
              "FAC              305\n",
              "LOC              245\n",
              "EVENT            113\n",
              "PRODUCT           72\n",
              "LANGUAGE          54\n",
              "LAW               46\n",
              "WORK_OF_ART       15\n",
              "QUANTITY          14\n",
              "MONEY              8\n",
              "PERCENT            4\n",
              "Name: ner, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VGTmltR4gLc",
        "outputId": "c7eaa463-93da-447d-ffa6-e95633b24549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "ner_df.loc[ner_df['ner'] == 'ORG'].word.value_counts().head(TOP_LIMIT)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tbt                119\n",
              "aww                118\n",
              "gop                 75\n",
              "nba                 50\n",
              "islam               41\n",
              "nd                  40\n",
              "allahsoil           34\n",
              "sma                 32\n",
              "ios                 30\n",
              "house               30\n",
              "cnn                 29\n",
              "aap                 28\n",
              "amazon              26\n",
              "eu                  25\n",
              "fed                 25\n",
              "nyc                 21\n",
              "fbi                 21\n",
              "bogota colombia     20\n",
              "congress            20\n",
              "apple               20\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1djjhPD65Nf",
        "outputId": "ae3c4674-c0f8-45e9-e64c-6b10bf624e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "ner_df.loc[ner_df['ner'] == 'GPE'].word.value_counts().head(TOP_LIMIT)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "america       225\n",
              "orlando       210\n",
              "london        182\n",
              "us            148\n",
              "florida        97\n",
              "uk             93\n",
              "japan          79\n",
              "india          78\n",
              "miami          72\n",
              "germany        54\n",
              "paris          54\n",
              "france         51\n",
              "russia         51\n",
              "texas          48\n",
              "spain          48\n",
              "new york       43\n",
              "england        41\n",
              "chicago        40\n",
              "california     38\n",
              "china          37\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlzZQIkD4gLY",
        "outputId": "ce2cfdda-c7d0-4852-9557-a06d66e85cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "ner_df.loc[ner_df['ner'] == 'PERSON'].word.value_counts().head(TOP_LIMIT)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "selfie                                                     114\n",
              "hu                                                          74\n",
              "trump                                                       57\n",
              "tbt                                                         50\n",
              "hillary                                                     42\n",
              "feminismiscancer feminismisterrorism feminismmuktbharat     40\n",
              "xx                                                          38\n",
              "don                                                         34\n",
              "christina grimmie                                           31\n",
              "stas                                                        30\n",
              "jo cox                                                      30\n",
              "sikh temple                                                 28\n",
              "donald trump                                                26\n",
              "tgif ff                                                     26\n",
              "god                                                         24\n",
              "jesus                                                       24\n",
              "clinton                                                     21\n",
              "eur gbp                                                     21\n",
              "regrann                                                     18\n",
              "dwd wetterwarnung starkes gewitter                          17\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xjEmKIX7Xku"
      },
      "source": [
        "**Вывод:** тип NER (GPE) оказался самым популярным."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MJDmIMI4gLe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXhDou-h4gLh"
      },
      "source": [
        "**Задание 2.**\n",
        "\n",
        "Используя библиотеку nltk, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? Для данного задания используем ограничение на количество символов во входном датасете (max_word_limit_spacy = 1000000), чтобы иметь возможность сравнить результаты работы Spacy и nltk. Обратите внимание, что nltk чувствителен к регистру.\n",
        "\n",
        "С помощью nltk выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZSRXMxY4gLi"
      },
      "source": [
        "string_tweet = combine_df.tweet.to_string()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MjSIC8f4gLk"
      },
      "source": [
        "string_tweet_tokenize = nltk.word_tokenize(string_tweet)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u184ajtF4gLn"
      },
      "source": [
        "string_tweet_tags = nltk.pos_tag(string_tweet_tokenize)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOVSKpsM4gLp"
      },
      "source": [
        "string_tweet_chunk = nltk.ne_chunk(string_tweet_tags)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y86ePuY34gLs",
        "outputId": "adb8f067-02de-4af7-f5d8-c7e343123bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "{(' '.join(c[0] for c in chunk), chunk.label() ) \\\n",
        " for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(string_tweet))) if hasattr(chunk, 'label') }"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('___', 'ORGANIZATION'),\n",
              " ('______________', 'ORGANIZATION'),\n",
              " ('_______________________', 'ORGANIZATION'),\n",
              " ('atÂ', 'ORGANIZATION'),\n",
              " ('babalargÃ¼nÃ¼', 'ORGANIZATION'),\n",
              " ('bearishÂ', 'ORGANIZATION'),\n",
              " ('braggingÂ', 'ORGANIZATION'),\n",
              " ('brÃ¼ssel', 'ORGANIZATION'),\n",
              " ('church..and', 'GPE'),\n",
              " ('eatmorecrÃ', 'ORGANIZATION'),\n",
              " ('en-ger-land', 'GPE'),\n",
              " ('euro2016Â', 'ORGANIZATION'),\n",
              " ('euro2016Â Â', 'ORGANIZATION'),\n",
              " ('felicitÃ', 'ORGANIZATION'),\n",
              " ('firstÂ', 'ORGANIZATION'),\n",
              " ('foiinÃ', 'ORGANIZATION'),\n",
              " ('fridayÂ', 'ORGANIZATION'),\n",
              " ('fÃªte', 'ORGANIZATION'),\n",
              " ('gÃ¼mbet', 'ORGANIZATION'),\n",
              " ('ilustraciÃ³n', 'ORGANIZATION'),\n",
              " ('inc.', 'ORGANIZATION'),\n",
              " ('l.a.', 'GPE'),\n",
              " ('marschfÃ¼rjesus', 'ORGANIZATION'),\n",
              " ('mr.', 'PERSON'),\n",
              " ('mr. paris', 'PERSON'),\n",
              " ('nycÂ', 'ORGANIZATION'),\n",
              " ('oilÂ', 'ORGANIZATION'),\n",
              " ('peace/sad', 'ORGANIZATION'),\n",
              " ('st.peter', 'ORGANIZATION'),\n",
              " ('sunflowerÂ', 'ORGANIZATION'),\n",
              " ('turÂ', 'ORGANIZATION'),\n",
              " ('u.s', 'GPE'),\n",
              " ('u.s.', 'GPE'),\n",
              " ('vysoÄ\\x8dina', 'ORGANIZATION'),\n",
              " ('whatÂ', 'ORGANIZATION'),\n",
              " ('zÃ¼rich', 'GPE'),\n",
              " ('ð\\x9f\\x93·', 'ORGANIZATION'),\n",
              " ('ó¾\\x93¯', 'ORGANIZATION')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p7453QM8ZQc"
      },
      "source": [
        "**Вывод:** в топ вошли не только организации, но и мусор\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NALiymkh4gLv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6wyLvHC4gLz"
      },
      "source": [
        "**Задание 3.**\n",
        "\n",
        "Какая из библиотек по вашему лучше отработала? Сравните качество полученных most_common NER и количество распознаных NER.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiUyCFR_4gLz"
      },
      "source": [
        "**Выводы:**\n",
        "\n",
        "    - обе бибилиотеки работают не идеально. Присутствуют ошибочные детекции;\n",
        "    - обе бибилиотеки есть смысл использовать только в паре с постобработкой;\n",
        "    - между библиотеками есть разница при работе со словами в зависимости от регистра;\n",
        "    - в топе распознавания именованных сущеностей: даты, персоны, организации;\n",
        "    - какая из библиотек лучше отработала - сказать затрудняюсь."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nXrgJPX4gL0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}